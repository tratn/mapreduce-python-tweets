{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c417f425-8d36-48e1-afaa-7e90b5bf8456",
   "metadata": {},
   "source": [
    "<h1> MapReduce implementation in Python for analyzing health news tweets </h1>\n",
    "\n",
    "<h3> Objective </h3> \n",
    "To implement a MapReduce framework in Python for parallel processing.\n",
    "\n",
    "<h3> Dataset </h3>\n",
    "\n",
    "The data was collected in 2015 using Twitter API. This dataset contains health news from more than 15 major health news agencies such as BBC, CNN, and NYT.\n",
    "\n",
    "\n",
    "<p>Source: https://archive.ics.uci.edu/ml/datasets/Health+News+in+Twitter</p>\n",
    "\n",
    "<p>Reference: Karami, A., Gangopadhyay, A., Zhou, B., & Kharrazi, H. (2017). Fuzzy approach topic discovery in health and medical corpora. International Journal of Fuzzy Systems, 1-12.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651203d0-1649-4bcf-b56c-51689263b754",
   "metadata": {},
   "source": [
    "<h3> Setting up </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b08b0b6-d197-4010-9803-176ee26c0cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import time \n",
    "import math \n",
    "import functools \n",
    "from multiprocessing import Pool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "604336c9-17e2-4b97-a07c-063e982bae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the paths for files\n",
    "src_dir = os.listdir('data/source')\n",
    "src_files = [i for i in src_dir if os.path.isdir(i) is False]\n",
    "src_folder = 'data/source'\n",
    "\n",
    "raw_folder = 'data/raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d346cad8-88d8-4314-8220-ad14b4feaa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data encoding\n",
    "\n",
    "from chardet import detect\n",
    "\n",
    "def get_encoding(file):\n",
    "    \"\"\" Given a file path, find the encoding type of the file \"\"\"\n",
    "    with open(file, 'rb') as f:\n",
    "        data = f.read()\n",
    "    return detect(data)['encoding']\n",
    "\n",
    "# Convert encoding of source files to utf-8 and stored as new files in raw folder \n",
    "for file_name in src_files: \n",
    "    src_file = os.path.join(src_folder, file_name)\n",
    "    encoded_file = os.path.join(raw_folder, file_name)\n",
    "    # get the original encoding \n",
    "    current_encoding = get_encoding(src_file)\n",
    "    with open(src_file, 'r', encoding=current_encoding, errors='ignore') as f:\n",
    "        with open(encoded_file, 'w+', encoding='utf-8', errors='ignore') as e: \n",
    "            data = f.read()\n",
    "            e.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee06ecb-6bc3-41d9-9dad-2bcd76c129ed",
   "metadata": {},
   "source": [
    "<h3> MapReduce framework </h3>\n",
    "\n",
    "In this step, we will implement our MapReduce function for processing the data. The steps are: \n",
    "1. Break data into chunks\n",
    "2. Use a mapper function to process each chunk of data \n",
    "3. Use a reducer function to combine results produced by mapper function \n",
    "\n",
    "The mapper and reducer functions can be tailored depending on the type of processing or analysis we want to perform on the data. The three steps described above can be generalised into a map_reduce function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b95bb72-a54c-4099-a16d-422753e2c90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement function to break data into chunks \n",
    "def create_chunks(data, num_chunks):\n",
    "    \"\"\"\n",
    "    Break data into desired number of chunks \n",
    "    Args:\n",
    "    data(list): The data to break into chunks \n",
    "    num_chunks(int): Number of chunks \n",
    "    \n",
    "    Returns: \n",
    "    list: a list of chunks of data \n",
    "    \"\"\"\n",
    "    # calculate chunk size \n",
    "    chunk_size = math.ceil(len(data)/num_chunks) \n",
    "    return [data[i:i+chunk_size] for i in range(0, len(data), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3a110d1-53bb-413a-9480-9e28d816a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement MapReduce function \n",
    "def map_reduce(data, num_processes, mapper, reducer): \n",
    "    \n",
    "    \"\"\"Run processes on a given set of data\n",
    "    Args: \n",
    "    data: the data to process \n",
    "    num_processes: number of processes to run in parallel \n",
    "    mapper: the function to map to each process \n",
    "    reducer: the function to combine results of mapper \n",
    "    \n",
    "    Returns:\n",
    "    The global result produced from reducer. \n",
    "    \n",
    "    \"\"\"\n",
    "    # break data into chunks \n",
    "    chunks = create_chunks(data, num_processes) \n",
    "    # apply mapper function to each chunk in parallel fashion \n",
    "    with Pool(num_processes) as pool: # create a pool of processes\n",
    "        chunk_results = pool.map(mapper, chunks)\n",
    "        # apply reducer function to results of mapper \n",
    "    overall_result = functools.reduce(reducer, chunk_results)\n",
    "    return overall_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa563340-4fbc-4740-baf6-c71ec37bcab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the encoded raw files\n",
    "raw_dir = os.listdir('data/raw') \n",
    "raw_files = [i for i in raw_dir if os.path.isdir(i) is False]\n",
    "data = []\n",
    "for file in raw_files: \n",
    "    with open(os.path.join(raw_folder, file)) as f: \n",
    "        lines = [line for line in f.readlines()]\n",
    "        data.append(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a62b34c-6de4-418b-b700-d076550293d7",
   "metadata": {},
   "source": [
    "<h3> Searching for occurence of a topic </h3> \n",
    "\n",
    "Given a keyword as topic, count the number of tweets and keep track of tweet IDs that contain the topic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b12c77ef-d4ea-4938-becb-d9876afcc8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools \n",
    "# import the mapper and reducer functions\n",
    "from mapper import mapper_count_topic \n",
    "from reducer import reducer_count_topic\n",
    "\n",
    "# prepare the data \n",
    "tweets_from_all_agencies = list(itertools.chain(*data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74f9f01c-e001-4be0-8379-acbcbdf8cf51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keyword': 'vaccines',\n",
       " 'count': 57,\n",
       " 'ids': ['575049588454858752',\n",
       "  '572575901025759232',\n",
       "  '572528136426004480',\n",
       "  '572509390789599232',\n",
       "  '572504407927078913',\n",
       "  '563170245184339969',\n",
       "  '563156321470799872',\n",
       "  '563133823014416384',\n",
       "  '512386620340043777',\n",
       "  '491373383708594177',\n",
       "  '484092846803517440',\n",
       "  '484084952745906176',\n",
       "  '459761474647646208',\n",
       "  '459453569813716992',\n",
       "  '459425265501085696',\n",
       "  '426072899012030464',\n",
       "  '292382429497421824',\n",
       "  '161992104862679040',\n",
       "  '581215093372878850',\n",
       "  '576030577008181248',\n",
       "  '571026422896173056',\n",
       "  '563093546367205376',\n",
       "  '563002551097102338',\n",
       "  '562335004802711552',\n",
       "  '561860255005822976',\n",
       "  '561278423424057344',\n",
       "  '560096182631157760',\n",
       "  '558336774599348224',\n",
       "  '557406204474163200',\n",
       "  '547533001677373441',\n",
       "  '530331709284548608',\n",
       "  '530076621752254466',\n",
       "  '526770084224970752',\n",
       "  '525303540869496833',\n",
       "  '525293713279692802',\n",
       "  '525209668550139904',\n",
       "  '525001078635769856',\n",
       "  '524591933864554497',\n",
       "  '517369325003747328',\n",
       "  '517354937224007680',\n",
       "  '517199713272356864',\n",
       "  '516225189433319427',\n",
       "  '516161733040566273',\n",
       "  '515499960545312769',\n",
       "  '511617079477559296',\n",
       "  '494475394787995648',\n",
       "  '487509864160051200',\n",
       "  '487379412539949056',\n",
       "  '199495187989401600',\n",
       "  '186842457378533379',\n",
       "  '157913715944075264',\n",
       "  '154725239786442752',\n",
       "  '141931790830026754',\n",
       "  '141168203404550144',\n",
       "  '136140583340224512',\n",
       "  '110818235720548352',\n",
       "  '106763993951109121']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for tweets with the keyword 'vaccines' \n",
    "result = map_reduce(tweets_from_all_agencies, 5, mapper_count_topic, reducer_count_topic)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c93f5f-caf7-4121-a983-4916ffd3e2cd",
   "metadata": {},
   "source": [
    "<h3> Displaying the contents of the match</h3> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17a77b08-cb6c-4cdc-bde7-e8624cc91e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_content_as_df(tweet_ids=[]):\n",
    "    \"\"\" Take a list of tweet ids and return the content as dataframe\"\"\" \n",
    "    # iterate through each tweet \n",
    "    # split by |, check for matching of first element \n",
    "    # if matched, grap third element as content, append to list called contents \n",
    "    # return as a dictionary: ids, contents\n",
    "    # return df from dict \n",
    "    matched_tweets = {'ids': [], 'contents': [] } \n",
    "    for tweet in tweets_from_all_agencies: \n",
    "        for tweet_id in tweet_ids: \n",
    "            split_tweet = tweet.split(\"|\")\n",
    "            if tweet_id in split_tweet: \n",
    "                matched_tweets['ids'].append(tweet_id)\n",
    "                matched_tweets['contents'].append(split_tweet[2]) \n",
    "    return pd.DataFrame(matched_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88cd75bd-24c5-4182-88eb-bbc10a026a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>575049588454858752</td>\n",
       "      <td>With Ebola crisis easing, efforts to test new ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>572575901025759232</td>\n",
       "      <td>74% of doctors surveyed said they have complie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>572528136426004480</td>\n",
       "      <td>Doctors often delay vaccines for young childre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>572509390789599232</td>\n",
       "      <td>Pediatricians and family medicine doctors feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>572504407927078913</td>\n",
       "      <td>Vaccine-wary parents pressure doctors to delay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>563170245184339969</td>\n",
       "      <td>When it comes to vaccines, random online comme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>563156321470799872</td>\n",
       "      <td>The good: People believed @CDCgov's advice abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>563133823014416384</td>\n",
       "      <td>On the Internet, the @CDCgov and random online...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>512386620340043777</td>\n",
       "      <td>Not having ANY Ebola drugs, vaccines is a prob...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Tweet ID                                            Content\n",
       "0  575049588454858752  With Ebola crisis easing, efforts to test new ...\n",
       "1  572575901025759232  74% of doctors surveyed said they have complie...\n",
       "2  572528136426004480  Doctors often delay vaccines for young childre...\n",
       "3  572509390789599232  Pediatricians and family medicine doctors feel...\n",
       "4  572504407927078913  Vaccine-wary parents pressure doctors to delay...\n",
       "5  563170245184339969  When it comes to vaccines, random online comme...\n",
       "6  563156321470799872  The good: People believed @CDCgov's advice abo...\n",
       "7  563133823014416384  On the Internet, the @CDCgov and random online...\n",
       "8  512386620340043777  Not having ANY Ebola drugs, vaccines is a prob..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = ['575049588454858752',\n",
    "  '572575901025759232',\n",
    "  '572528136426004480',\n",
    "  '572509390789599232',\n",
    "  '572504407927078913',\n",
    "  '563170245184339969',\n",
    "  '563156321470799872',\n",
    "  '563133823014416384',\n",
    "  '512386620340043777'] \n",
    "\n",
    "result_df = display_content_as_df(ids)\n",
    "result_df.columns = ['Tweet ID', 'Content'] \n",
    "result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
